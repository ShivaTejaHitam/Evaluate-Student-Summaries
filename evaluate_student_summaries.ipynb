{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Import the required libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-21T18:16:30.005720Z","iopub.execute_input":"2023-09-21T18:16:30.006192Z","iopub.status.idle":"2023-09-21T18:16:30.011956Z","shell.execute_reply.started":"2023-09-21T18:16:30.006141Z","shell.execute_reply":"2023-09-21T18:16:30.010441Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"**Load the Datasets**","metadata":{}},{"cell_type":"code","source":"prompts_train_dataset = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\nprint(\"Full prompts train dataset shape is \",prompts_train_dataset.shape)\nsummaries_train_dataset = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\nprint(\"Full summaries train dataset shape is \",summaries_train_dataset.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:30.019480Z","iopub.execute_input":"2023-09-21T18:16:30.020871Z","iopub.status.idle":"2023-09-21T18:16:30.109282Z","shell.execute_reply.started":"2023-09-21T18:16:30.020816Z","shell.execute_reply":"2023-09-21T18:16:30.107863Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Full prompts train dataset shape is  (4, 4)\nFull summaries train dataset shape is  (7165, 5)\n","output_type":"stream"}]},{"cell_type":"code","source":"prompts_train_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:30.111880Z","iopub.execute_input":"2023-09-21T18:16:30.112365Z","iopub.status.idle":"2023-09-21T18:16:30.127128Z","shell.execute_reply.started":"2023-09-21T18:16:30.112312Z","shell.execute_reply":"2023-09-21T18:16:30.125644Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"  prompt_id                                    prompt_question  \\\n0    39c16e  Summarize at least 3 elements of an ideal trag...   \n1    3b9047  In complete sentences, summarize the structure...   \n2    814d6b  Summarize how the Third Wave developed over su...   \n3    ebad26  Summarize the various ways the factory would u...   \n\n                prompt_title  \\\n0                 On Tragedy   \n1  Egyptian Social Structure   \n2             The Third Wave   \n3    Excerpt from The Jungle   \n\n                                         prompt_text  \n0  Chapter 13 \\r\\nAs the sequel to what has alrea...  \n1  Egyptian society was structured like a pyramid...  \n2  Background \\r\\nThe Third Wave experiment took ...  \n3  With one member trimming beef in a cannery, an...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39c16e</td>\n      <td>Summarize at least 3 elements of an ideal trag...</td>\n      <td>On Tragedy</td>\n      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3b9047</td>\n      <td>In complete sentences, summarize the structure...</td>\n      <td>Egyptian Social Structure</td>\n      <td>Egyptian society was structured like a pyramid...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>814d6b</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ebad26</td>\n      <td>Summarize the various ways the factory would u...</td>\n      <td>Excerpt from The Jungle</td>\n      <td>With one member trimming beef in a cannery, an...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"summaries_train_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:30.129365Z","iopub.execute_input":"2023-09-21T18:16:30.129981Z","iopub.status.idle":"2023-09-21T18:16:30.147679Z","shell.execute_reply.started":"2023-09-21T18:16:30.129917Z","shell.execute_reply":"2023-09-21T18:16:30.146034Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"     student_id prompt_id                                               text  \\\n0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n\n    content   wording  \n0  0.205683  0.380538  \n1 -0.548304  0.506755  \n2  3.128928  4.231226  \n3 -0.210614 -0.471415  \n4  3.272894  3.219757  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000e8c3c7ddb</td>\n      <td>814d6b</td>\n      <td>The third wave was an experimentto see how peo...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0020ae56ffbf</td>\n      <td>ebad26</td>\n      <td>They would rub it up with soda to make the sme...</td>\n      <td>-0.548304</td>\n      <td>0.506755</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>004e978e639e</td>\n      <td>3b9047</td>\n      <td>In Egypt, there were many occupations and soci...</td>\n      <td>3.128928</td>\n      <td>4.231226</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>005ab0199905</td>\n      <td>3b9047</td>\n      <td>The highest class was Pharaohs these people we...</td>\n      <td>-0.210614</td>\n      <td>-0.471415</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0070c9e7af47</td>\n      <td>814d6b</td>\n      <td>The Third Wave developed  rapidly because the ...</td>\n      <td>3.272894</td>\n      <td>3.219757</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Merge the Prompts and Summaries Datasets**","metadata":{}},{"cell_type":"code","source":"train_dataset = summaries_train_dataset.merge(prompts_train_dataset,on='prompt_id')\ntrain_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:30.150904Z","iopub.execute_input":"2023-09-21T18:16:30.151336Z","iopub.status.idle":"2023-09-21T18:16:30.182035Z","shell.execute_reply.started":"2023-09-21T18:16:30.151301Z","shell.execute_reply":"2023-09-21T18:16:30.180713Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"     student_id prompt_id                                               text  \\\n0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n1  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n2  0095993991fe    814d6b  The third wave only started as an experiment w...   \n3  00c20c6ddd23    814d6b  The experimen was orginally about how even whe...   \n4  00d40ad10dc9    814d6b  The third wave developed so quickly due to the...   \n\n    content   wording                                    prompt_question  \\\n0  0.205683  0.380538  Summarize how the Third Wave developed over su...   \n1  3.272894  3.219757  Summarize how the Third Wave developed over su...   \n2  0.205683  0.380538  Summarize how the Third Wave developed over su...   \n3  0.567975  0.969062  Summarize how the Third Wave developed over su...   \n4 -0.910596 -0.081769  Summarize how the Third Wave developed over su...   \n\n     prompt_title                                        prompt_text  \n0  The Third Wave  Background \\r\\nThe Third Wave experiment took ...  \n1  The Third Wave  Background \\r\\nThe Third Wave experiment took ...  \n2  The Third Wave  Background \\r\\nThe Third Wave experiment took ...  \n3  The Third Wave  Background \\r\\nThe Third Wave experiment took ...  \n4  The Third Wave  Background \\r\\nThe Third Wave experiment took ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>content</th>\n      <th>wording</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000e8c3c7ddb</td>\n      <td>814d6b</td>\n      <td>The third wave was an experimentto see how peo...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0070c9e7af47</td>\n      <td>814d6b</td>\n      <td>The Third Wave developed  rapidly because the ...</td>\n      <td>3.272894</td>\n      <td>3.219757</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0095993991fe</td>\n      <td>814d6b</td>\n      <td>The third wave only started as an experiment w...</td>\n      <td>0.205683</td>\n      <td>0.380538</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00c20c6ddd23</td>\n      <td>814d6b</td>\n      <td>The experimen was orginally about how even whe...</td>\n      <td>0.567975</td>\n      <td>0.969062</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00d40ad10dc9</td>\n      <td>814d6b</td>\n      <td>The third wave developed so quickly due to the...</td>\n      <td>-0.910596</td>\n      <td>-0.081769</td>\n      <td>Summarize how the Third Wave developed over su...</td>\n      <td>The Third Wave</td>\n      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Calculate the numeric features from the dataset.**","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nimport string\nimport re\n\ndef count_syllables(word):\n    vowels = \"aeiouAEIOU\"\n    count = 0\n    for char in word:\n        if char in vowels:\n            count += 1\n    return count\n\ndef calculate_reading_ease(text):\n    words = re.findall(r'\\b\\w+\\b', text)\n    \n    total_words = len(words)\n    sentences = re.split(r'[.!?]', text)\n    total_sentences = len(sentences)\n    total_syllables = sum(count_syllables(word) for word in words)\n    \n    reading_ease = 206.835 - 1.015 * (total_words / total_sentences) - 84.6 * (total_syllables / total_words)\n    \n    return reading_ease\n\ndef count_punctuation(text):\n    punctuation_set = set(string.punctuation)\n    punctuation_count = sum(1 for char in text if char in punctuation_set)\n    return punctuation_count\n\ndef remove_punctuation(text):\n    translator = str.maketrans('', '', string.punctuation)\n    text_without_punctuation = text.translate(translator)\n    return text_without_punctuation\n\ndef count_stopwords(text):\n    stopword_list = set(stopwords.words('english'))\n    words = text.split()\n    stopwords_count = sum(1 for word in words if word.lower() in stopword_list)\n    return stopwords_count\n\ndef remove_stopwords(text):\n    words = text.split()\n    \n    stop_words = set(stopwords.words('english'))\n    \n    filtered_words = [word for word in words if word.lower() not in stop_words]\n    \n    filtered_text = ' '.join(filtered_words)\n    \n    return filtered_text\n\ndef find_word_overlap_ratio(essay, summary):\n    essay = remove_punctuation(essay)\n    essay = remove_stopwords(essay)\n    summary = remove_punctuation(summary)\n    summary = remove_stopwords(summary)\n\n    essay_words = essay.split()\n    summary_words = summary.split()\n\n    essay_word_set = set(essay_words)\n    summary_word_set = set(summary_words)\n\n    overlapping_words = essay_word_set.intersection(summary_word_set)\n    overlap_count = len(overlapping_words)\n\n    if len(essay_words) == 0:\n        return 0.0\n    else:\n        ratio = overlap_count / len(essay_words)\n        return ratio * 100\n\ndef find_disjoint_words_ratio(essay,summary):\n    essay = remove_punctuation(essay)\n    essay = remove_stopwords(essay)\n    summary = remove_punctuation(summary)\n    summary = remove_stopwords(summary)\n\n    essay_words = essay.split()\n    summary_words = summary.split()\n\n    essay_word_set = set(essay_words)\n    summary_word_set = set(summary_words)\n\n    overlapping_words = essay_word_set.difference(summary_word_set)\n    overlap_count = len(overlapping_words)\n\n    if len(essay_words) == 0:\n        return 0.0\n    else:\n        ratio = overlap_count / len(essay_words)\n        return ratio * 100","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:30.184612Z","iopub.execute_input":"2023-09-21T18:16:30.185114Z","iopub.status.idle":"2023-09-21T18:16:30.207204Z","shell.execute_reply.started":"2023-09-21T18:16:30.185068Z","shell.execute_reply":"2023-09-21T18:16:30.205592Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def feature_engineer(dataset,feature = 'text'):\n    dataset[feature+'_length'] = dataset[feature].apply(lambda x : len(x))\n    dataset['punctuations_count'] = dataset[feature].apply(lambda x : count_punctuation(x))\n    dataset['stop_words_count'] = dataset[feature].apply(lambda x : count_stopwords(x))\n    dataset['reading_ease'] = dataset[feature].apply(lambda x : calculate_reading_ease(x))\n    dataset['word_overlap_ratio'] = dataset.apply(lambda x : find_word_overlap_ratio(x['prompt_text'],x[feature]),axis=1)\n    dataset['disjoint_words_ratio'] = dataset.apply(lambda x : find_disjoint_words_ratio(x['prompt_text'],x[feature]),axis=1)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:30.209823Z","iopub.execute_input":"2023-09-21T18:16:30.210427Z","iopub.status.idle":"2023-09-21T18:16:30.225510Z","shell.execute_reply.started":"2023-09-21T18:16:30.210375Z","shell.execute_reply":"2023-09-21T18:16:30.224266Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"**Extract Feature Columns from the dataset for Content and Wording**","metadata":{}},{"cell_type":"code","source":"train_dataset = feature_engineer(train_dataset)\ncontent_score = train_dataset['content']\nwording_score = train_dataset['wording']\nwording_feature_columns = train_dataset.drop(columns=['prompt_id','prompt_question','prompt_title','student_id','prompt_text','text','content','wording'],axis=1)\ncontent_feature_columns = wording_feature_columns","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:30.228337Z","iopub.execute_input":"2023-09-21T18:16:30.228760Z","iopub.status.idle":"2023-09-21T18:16:49.298160Z","shell.execute_reply.started":"2023-09-21T18:16:30.228726Z","shell.execute_reply":"2023-09-21T18:16:49.296779Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"**Split the Dataset in to Train and Test data**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nContent_train,Content_test , content_score_train , content_score_test = train_test_split(content_feature_columns,content_score,test_size=0.2, random_state=42)\nWording_train,Wording_test , wording_score_train , wording_score_test = train_test_split(wording_feature_columns,wording_score,test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:49.299969Z","iopub.execute_input":"2023-09-21T18:16:49.300396Z","iopub.status.idle":"2023-09-21T18:16:49.313750Z","shell.execute_reply.started":"2023-09-21T18:16:49.300359Z","shell.execute_reply":"2023-09-21T18:16:49.312275Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"**Train the model**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\ncontent_model = RandomForestRegressor()\ncontent_model.fit(Content_train,content_score_train)\nwording_model = RandomForestRegressor()\nwording_model.fit(Wording_train,wording_score_train)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:49.316582Z","iopub.execute_input":"2023-09-21T18:16:49.317043Z","iopub.status.idle":"2023-09-21T18:16:54.524087Z","shell.execute_reply.started":"2023-09-21T18:16:49.317000Z","shell.execute_reply":"2023-09-21T18:16:54.522778Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"RandomForestRegressor()","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Trying Predicting the Summary Scores using Test Data**","metadata":{}},{"cell_type":"code","source":"content_pred = content_model.predict(Content_test)\nwording_pred = wording_model.predict(Wording_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:54.525720Z","iopub.execute_input":"2023-09-21T18:16:54.527991Z","iopub.status.idle":"2023-09-21T18:16:54.671928Z","shell.execute_reply.started":"2023-09-21T18:16:54.527924Z","shell.execute_reply":"2023-09-21T18:16:54.670564Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"****Calculate the Model Metrics****","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\ncontent_mse = mean_squared_error(content_score_test,content_pred)\nwording_mse = mean_squared_error(wording_score_test,wording_pred)\nprint('content_mse is ',content_mse)\nprint('wording_mse is ',wording_mse)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:54.673559Z","iopub.execute_input":"2023-09-21T18:16:54.674061Z","iopub.status.idle":"2023-09-21T18:16:54.683416Z","shell.execute_reply.started":"2023-09-21T18:16:54.674027Z","shell.execute_reply":"2023-09-21T18:16:54.681907Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"content_mse is  0.22413143348110004\nwording_mse is  0.4060478640040543\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Submission**","metadata":{}},{"cell_type":"code","source":"df_test_prompt = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_test.csv')\ndf_test_summaries = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:54.685432Z","iopub.execute_input":"2023-09-21T18:16:54.685883Z","iopub.status.idle":"2023-09-21T18:16:54.709480Z","shell.execute_reply.started":"2023-09-21T18:16:54.685832Z","shell.execute_reply":"2023-09-21T18:16:54.707955Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"df_test = df_test_summaries.merge(df_test_prompt, on='prompt_id')","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:54.711016Z","iopub.execute_input":"2023-09-21T18:16:54.711466Z","iopub.status.idle":"2023-09-21T18:16:54.722624Z","shell.execute_reply.started":"2023-09-21T18:16:54.711424Z","shell.execute_reply":"2023-09-21T18:16:54.721224Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"processed_test_df = feature_engineer(df_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:54.727156Z","iopub.execute_input":"2023-09-21T18:16:54.728000Z","iopub.status.idle":"2023-09-21T18:16:54.749241Z","shell.execute_reply.started":"2023-09-21T18:16:54.727959Z","shell.execute_reply":"2023-09-21T18:16:54.747603Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"test_ds = processed_test_df[content_feature_columns.columns.to_list()]","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:54.750876Z","iopub.execute_input":"2023-09-21T18:16:54.751314Z","iopub.status.idle":"2023-09-21T18:16:54.759408Z","shell.execute_reply.started":"2023-09-21T18:16:54.751275Z","shell.execute_reply":"2023-09-21T18:16:54.757949Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"processed_test_df['content'] = content_model.predict(test_ds)\nprocessed_test_df['wording'] = wording_model.predict(test_ds)","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:54.761085Z","iopub.execute_input":"2023-09-21T18:16:54.761779Z","iopub.status.idle":"2023-09-21T18:16:54.801596Z","shell.execute_reply.started":"2023-09-21T18:16:54.761737Z","shell.execute_reply":"2023-09-21T18:16:54.800281Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"processed_test_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:54.803100Z","iopub.execute_input":"2023-09-21T18:16:54.803685Z","iopub.status.idle":"2023-09-21T18:16:54.827141Z","shell.execute_reply.started":"2023-09-21T18:16:54.803639Z","shell.execute_reply":"2023-09-21T18:16:54.825810Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"     student_id prompt_id            text prompt_question     prompt_title  \\\n0  000000ffffff    abc123  Example text 1    Summarize...  Example Title 1   \n1  222222cccccc    abc123  Example text 3    Summarize...  Example Title 1   \n2  111111eeeeee    def789  Example text 2    Summarize...  Example Title 2   \n3  333333dddddd    def789  Example text 4    Summarize...  Example Title 2   \n\n        prompt_text  text_length  punctuations_count  stop_words_count  \\\n0  Heading\\nText...           14                   0                 0   \n1  Heading\\nText...           14                   0                 0   \n2  Heading\\nText...           14                   0                 0   \n3  Heading\\nText...           14                   0                 0   \n\n   reading_ease  word_overlap_ratio  disjoint_words_ratio   content   wording  \n0         90.99                 0.0                 100.0 -1.400718 -1.294038  \n1         90.99                 0.0                 100.0 -1.400718 -1.294038  \n2         90.99                 0.0                 100.0 -1.400718 -1.294038  \n3         90.99                 0.0                 100.0 -1.400718 -1.294038  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>prompt_question</th>\n      <th>prompt_title</th>\n      <th>prompt_text</th>\n      <th>text_length</th>\n      <th>punctuations_count</th>\n      <th>stop_words_count</th>\n      <th>reading_ease</th>\n      <th>word_overlap_ratio</th>\n      <th>disjoint_words_ratio</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>abc123</td>\n      <td>Example text 1</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>90.99</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>-1.400718</td>\n      <td>-1.294038</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>222222cccccc</td>\n      <td>abc123</td>\n      <td>Example text 3</td>\n      <td>Summarize...</td>\n      <td>Example Title 1</td>\n      <td>Heading\\nText...</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>90.99</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>-1.400718</td>\n      <td>-1.294038</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>111111eeeeee</td>\n      <td>def789</td>\n      <td>Example text 2</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>90.99</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>-1.400718</td>\n      <td>-1.294038</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>def789</td>\n      <td>Example text 4</td>\n      <td>Summarize...</td>\n      <td>Example Title 2</td>\n      <td>Heading\\nText...</td>\n      <td>14</td>\n      <td>0</td>\n      <td>0</td>\n      <td>90.99</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>-1.400718</td>\n      <td>-1.294038</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"processed_test_df[['student_id', 'content', 'wording']].to_csv('submission.csv',index=False)\ndisplay(pd.read_csv('submission.csv'))","metadata":{"execution":{"iopub.status.busy":"2023-09-21T18:16:54.829627Z","iopub.execute_input":"2023-09-21T18:16:54.830308Z","iopub.status.idle":"2023-09-21T18:16:54.853742Z","shell.execute_reply.started":"2023-09-21T18:16:54.830256Z","shell.execute_reply":"2023-09-21T18:16:54.852131Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"     student_id   content   wording\n0  000000ffffff -1.400718 -1.294038\n1  222222cccccc -1.400718 -1.294038\n2  111111eeeeee -1.400718 -1.294038\n3  333333dddddd -1.400718 -1.294038","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>student_id</th>\n      <th>content</th>\n      <th>wording</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000000ffffff</td>\n      <td>-1.400718</td>\n      <td>-1.294038</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>222222cccccc</td>\n      <td>-1.400718</td>\n      <td>-1.294038</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>111111eeeeee</td>\n      <td>-1.400718</td>\n      <td>-1.294038</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>333333dddddd</td>\n      <td>-1.400718</td>\n      <td>-1.294038</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}